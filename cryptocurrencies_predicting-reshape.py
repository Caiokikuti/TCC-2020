# -*- coding: utf-8 -*-
"""cryptocurrencies-predicting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13Tm-ZnYIxUd_TGftUPl0mfQnXdwwH1qD
"""

#New LSTM to predict bitcoin values
import math
import pandas_datareader as web
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn import preprocessing
from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout, BatchNormalization
import matplotlib.pyplot as plt
from collections import deque
import tensorflow as tf
from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint
from sklearn import metrics
import random
import time
# from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback


plt.style.use('fivethirtyeight')

SEQ_LEN = 30
FUTURE_PERIOD_PREDICT = 1
EPOCHS = 3
BATCH_SIZE = 128
NAME = f"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}"

#Getting BTC-USD data
df = web.DataReader('BTC-USD', data_source='yahoo', start='2014-09-16', end='2019-12-30')
#show the data
df

def classify(current, future):
  if float(future) > float(current):
    return 1
  else:
    return 0

def preprocess_df(df):
  df = df.drop('future', 1)

  for col in df.columns:
    if col != "target":
      df[col] = df[col].pct_change()
      df.dropna(inplace=True)
      df[col] = preprocessing.scale(df[col].values)

  df.dropna(inplace=True)

  sequential_data = []
  prev_days = deque(maxlen=SEQ_LEN)

  for i in df.values:
    
    prev_days.append([n for n in i[:-1]])
    
    if len(prev_days) == SEQ_LEN:
      sequential_data.append([np.array(prev_days), i[-1]])
  
  random.shuffle(sequential_data)

  buys = []
  sells = []

  for seq, target in sequential_data:
    if target == 0:
      sells.append([seq, target])
    else:
      buys.append([seq, target])

  random.shuffle(buys)
  random.shuffle(sells)

  lower = min(len(buys), len(sells))

  sequential_data = buys+sells
  random.shuffle(sequential_data)

  x = []
  y = []

  for seq, target in sequential_data:
    x.append(seq)
    y.append(target)

  return np.array(x), np.array(y)

# catalogando os dados para prever 1 dia no futuro
df['future'] = df['Close'].shift(-FUTURE_PERIOD_PREDICT)

df['target'] = list(map(classify, df['Close'], df['future']))
df.dropna(inplace=True)

df

#Definindo o tamanho do conjunto de teste
times = sorted(df.index.values)
last_5pct = times[-int(0.05*len(times))]
print(last_5pct)

validation_main_df = df[(df.index >= last_5pct)]
main_df = df[df.index < last_5pct]

print(validation_main_df.shape)
print(main_df. shape)
validation_main_df

train_x, train_y = preprocess_df(main_df)
validation_x, validation_y = preprocess_df(validation_main_df)
print(train_y.shape)

print(f"train data: {len(train_x)} validation: {len(validation_x)}")
print(f"Dont buys: {len(train_y)}, buys: {len(validation_y)}")
print(f"VALIDATION Dont buys: {len(validation_y)}, buys: {len(validation_y)}")

model = Sequential()
model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(LSTM(128, input_shape=(train_x.shape[1:])))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(Dense(32, activation="relu"))
model.add(Dropout(0.2))

model.add(Dense(2, activation="softmax"))

opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)
model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy', "binary_accuracy"])

#Saving information for the tensorboard
tensorboard = TensorBoard(log_dir="logs/{}".format(NAME))

filepath = "RNN_Final-{epoch:02d}-{val_accuracy:.3f}"  # unique file name that will include the epoch and the validation acc for that epoch
checkpoint = ModelCheckpoint("models/{}.model".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones

# Train model
history = model.fit(
    train_x, train_y,
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=(validation_x, validation_y),
    callbacks=[tensorboard, checkpoint])

# Score model
score = model.evaluate(validation_x, validation_y, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# Save model
model.save("models/{}".format(NAME))

def preprocess_df2(df):
  df = df.drop('future', 1)

  for col in df.columns:
    if col != "target":
      df[col] = df[col].pct_change()
      df.dropna(inplace=True)
      df[col] = preprocessing.scale(df[col].values)

  df.dropna(inplace=True)

  sequential_data = []
  prev_days = deque(maxlen=30)

  for i in df.values:
    
    prev_days.append([n for n in i[:-1]])
    
    if len(prev_days) == 30:
      sequential_data.append([np.array(prev_days), i[-1]])  

  x = []
  y = []

  for seq, target in sequential_data:
    x.append(seq)
    y.append(target)

  return np.array(x), np.array(y)

df2 = web.DataReader('BTC-USD', data_source='yahoo', start='2019-11-27', end='2020-12-31')
df2['future'] = df2['Close'].shift(-FUTURE_PERIOD_PREDICT)

df2['target'] = list(map(classify, df2['Close'], df2['future']))
df2.dropna(inplace=True)
print(df2.shape)
setx, sety = preprocess_df2(df2)
print(setx.shape)
df2

prediction = model.predict(setx)
classes = np.argmax(prediction, axis = 1)
print(classes.shape)
print(f'F1-Score: {metrics.f1_score(classes,sety)}')

df3 = web.DataReader('BTC-USD', data_source='yahoo', start='2020-01-01', end='2020-12-31')
df3['future'] = df3['Close'].shift(-FUTURE_PERIOD_PREDICT)

df3['target'] = list(map(classify, df3['Close'], df3['future']))
df3.dropna(inplace=True)

df3['prediction'] = classes
df3.to_csv('./OUTPUT_LSTM_reshape2')